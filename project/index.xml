<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Ajay Unagar</title>
    <link>https://aunagar.github.io/project/</link>
      <atom:link href="https://aunagar.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 01 Feb 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://aunagar.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://aunagar.github.io/project/</link>
    </image>
    
    <item>
      <title>Learning to calibrate battery models using Deep Reinforcement Learning</title>
      <link>https://aunagar.github.io/project/rlbattery/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://aunagar.github.io/project/rlbattery/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Lithium-Ion (Li-I) batteries are used in many physical assets. To enable a good prediction of the end of discharge of batteries, detailed electrochemical Li-I battery models have been developed. However, these battery models need to be calibrated regularly as the batteries degrade. In this paper, we implement a model-free Reinforcement Learning-based framework for reliably and efficiently inferring calibration parameters of battery models. The framework enables real-time inference of the battery degradation parameters in order to compensate the reality-gap from the observations. Most importantly, the proposed methodology does not need any labeled data samples, (samples of observations and the ground truth calibration parameters). Furthermore, to increase the stability of the parameter inference, we incorporate lyapunov energy decreasing condition as a regularizer for our policy network objective. Lyapunov regularizer enables that the inference tracking of the parameters converges to an optimal, no matter the initial condition. The experiments show impressive results compared to Kalman Filter-based approaches. Moreover, this framework is highly general and can be employed in calibration of other computational models.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Deep-direct Visual Localization using learned feature optimization</title>
      <link>https://aunagar.github.io/project/3dvision/</link>
      <pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://aunagar.github.io/project/3dvision/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Visual Localization plays important role in development of autonomous systems such as cars and drones. Traditional localization pipeline works in multiple phase: (a) retrieving nearest images from reference database (b) detecting and matching features, and (c) estimating pose from the matched features. In this project, we try to combine (b) and (c) and design algorithm for direct camera pose estimation for a query image given a (query, reference) pair. To design a direct localization algorithm, we use learned CNN features and optimize the pose for a query image to minimize the feature error between a query and a reference image pair. We &lt;a href=&#34;https://aunagar.github.io/publication/cvpr20203dv/cvpr20203dv.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;presented&lt;/a&gt; initial results of this work at CVPR 2020 workshop &lt;a href=&#34;https://sites.google.com/view/vislocslamcvpr2020/home?authuser=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VisLocOdomMap&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Continual Learning in Image Classification</title>
      <link>https://aunagar.github.io/project/clibm/</link>
      <pubDate>Sat, 31 Oct 2020 00:00:00 +0000</pubDate>
      <guid>https://aunagar.github.io/project/clibm/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Deep Neural Networks (DNNs) have been successfully applied to many problems in the medical domain. However, the common assumption of having access to the complete training data may not always hold true. Instead, data could be provided by different sources at different points in time. Especially in the medical field, privacy regulations can exacerbate this problem by prohibiting storage of old data. In such scenarios, proper incremental training for DNNs becomes essential to not forget previously learned knowledge. To this end, a recently published method called Deep Model Consolidation (DMC) proposes knowledge distillation with auxiliary data. We use this method as a benchmark and propose improvements on top of it. Furthermore, we present a novel approach to transform auxiliary images to look more like images from old datasets. With experiments on known benchmark datasets as well as a dataset for tissue type classification, we show that DMC and our image transformer-based method can reduce forgetting of previously acquired knowledge.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Making robots dance (in simulation)</title>
      <link>https://aunagar.github.io/project/robodance/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://aunagar.github.io/project/robodance/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;In this project, we used inverse kinematics (IK) to build simple walking gaits for the hexapod. Furthermore, these walking gaits were combined using a motion graph to create complicated motion trajectories for the robot. Furthermore, we used these gaits along with the target following objective to make robot autonomously move to the target position. We also design pre-specified gaits using motion graph, which allow robot to &lt;a href=&#34;https://youtu.be/c9aaSq0QW1I?t=246&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dance&lt;/a&gt;!&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Parallel algorithms for Subgraph Isomorphism (OpenMP and MPI)</title>
      <link>https://aunagar.github.io/project/hpc/</link>
      <pubDate>Fri, 27 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://aunagar.github.io/project/hpc/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;We proposed two parallel implementations of popular subgraph isomorphism solvers: VF2 and Glasgow. The recursive DFS in VF2 was parallelized using OpenMP tasks, and we aimed to limit the excessive work done by additional threads. In Glasgow, we parallelized the complete algorithm using OpenMP, and we put special attention to compiler optimizations and OpenMP task amount limitation. Furthermore, a large section of Glasgow was parallelized with MPI one-sided communication. All the implementations are benchmarked on a wide range of graph pairs from literature, and we compare our Glasgow OpenMP implementation with the parallel version proposed by the author of Glasgow algorithm. We discuss when good scaling can be expected, and where improvements are possible.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
