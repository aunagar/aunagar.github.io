<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reinforcement Learning | Ajay Unagar</title>
    <link>http://localhost:1313/tag/reinforcement-learning/</link>
      <atom:link href="http://localhost:1313/tag/reinforcement-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Reinforcement Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 31 Oct 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Reinforcement Learning</title>
      <link>http://localhost:1313/tag/reinforcement-learning/</link>
    </image>
    
    <item>
      <title>Global Path Planning in a Digital-Twin</title>
      <link>http://localhost:1313/project/rslthesis/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/rslthesis/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;The global path planning problem focuses on finding a safe and short path for the
robot to traverse between two places in the world. A Digital-Twin of the real-world
represents most of the information required for path planning. In this thesis we
present methods that use the Digital-Twin of the environment as a prior and build
navigation graphs. These navigation graphs are used for real-time path planning
during robotsâ€™ autonomous operation. First, we show a simulation based approach
that builds a navigation graph on a large triangular mesh of an environment. We
also show planned paths of more than 100m in length, spanning indoor and out-
door terrains, and passing through multiple floors. Second, we propose a deep
learning-based navigation cost predictor from the point-cloud data. This trained
cost predictor can be used to build the navigation graphs an order of magnitude
faster than the simulation-based approach. We also demonstrate that how our
point-cloud-based navigation cost predictor helps in real-time global re-planning to
handle large static map changes.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Learning to calibrate battery models using Deep Reinforcement Learning</title>
      <link>http://localhost:1313/project/rlbattery/</link>
      <pubDate>Mon, 01 Feb 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/rlbattery/</guid>
      <description>&lt;div style=&#34;text-align: justify&#34;&gt;
&lt;p&gt;Lithium-Ion (Li-I) batteries are used in many physical assets. To enable a good prediction of the end of discharge of batteries, detailed electrochemical Li-I battery models have been developed. However, these battery models need to be calibrated regularly as the batteries degrade. In this paper, we implement a model-free Reinforcement Learning-based framework for reliably and efficiently inferring calibration parameters of battery models. The framework enables real-time inference of the battery degradation parameters in order to compensate the reality-gap from the observations. Most importantly, the proposed methodology does not need any labeled data samples, (samples of observations and the ground truth calibration parameters). Furthermore, to increase the stability of the parameter inference, we incorporate lyapunov energy decreasing condition as a regularizer for our policy network objective. Lyapunov regularizer enables that the inference tracking of the parameters converges to an optimal, no matter the initial condition. The experiments show impressive results compared to Kalman Filter-based approaches. Moreover, this framework is highly general and can be employed in calibration of other computational models.&lt;/p&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Battery Model Calibration with Deep Reinforcement Learning</title>
      <link>http://localhost:1313/publication/neurips2020/</link>
      <pubDate>Thu, 31 Dec 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/neurips2020/</guid>
      <description>&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
